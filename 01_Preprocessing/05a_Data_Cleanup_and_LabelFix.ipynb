{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b2c897-420b-4caa-82e8-9850d4b1dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\install\\xgboost-3.0.2-py3-none-win_amd64.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from xgboost==3.0.2) (2.2.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from xgboost==3.0.2) (1.15.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install C:\\install\\xgboost-3.0.2-py3-none-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966ed7b0-1512-4b31-a524-8f351b747c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… XGBoost version: 3.0.2\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(\"âœ… XGBoost version:\", xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83fbeeb0-8d84-434e-9913-cc3af7a29633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (115029, 89)\n",
      "âœ… Test shape: (28758, 89)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1  0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 48\u001b[0m\n\u001b[0;32m     36\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     37\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     38\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# âœ… Step 5. Train the model\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… XGBoost training completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# âœ… Step 6. Make predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1640\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1635\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1637\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1639\u001b[0m ):\n\u001b[1;32m-> 1640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1642\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1643\u001b[0m     )\n\u001b[0;32m   1645\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1  0]"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# ðŸ“ 5-Model Training and Evaluation\n",
    "# ðŸ““ 02_Baseline_XGBoost_Implementation.ipynb\n",
    "# -------------------------------------------------\n",
    "\n",
    "# âœ… Step 0. Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# âœ… Step 1. Load cleaned train-test split data\n",
    "train_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\train_data.csv\"\n",
    "test_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\test_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"âœ… Train shape:\", train_df.shape)\n",
    "print(\"âœ… Test shape:\", test_df.shape)\n",
    "\n",
    "# âœ… Step 2. Separate features and labels\n",
    "X_train = train_df.drop(columns=['Label', 'Attack_enc', 'Label_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack'], errors='ignore')\n",
    "y_train = train_df['Label_enc']\n",
    "\n",
    "X_test = test_df.drop(columns=['Label', 'Attack_enc', 'Label_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack'], errors='ignore')\n",
    "y_test = test_df['Label_enc']\n",
    "\n",
    "# âœ… Step 3. Convert labels to int if needed\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# âœ… Step 4. Initialise XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# âœ… Step 5. Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"âœ… XGBoost training completed.\")\n",
    "\n",
    "# âœ… Step 6. Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"âœ… Predictions completed.\")\n",
    "\n",
    "# âœ… Step 7. Evaluate performance\n",
    "print(\"ðŸ”Ž Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# âœ… Step 8. Confusion Matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# âœ… Step 9. Save evaluation outputs for reporting\n",
    "report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "report_df.to_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\xgb_baseline_classification_report.csv\")\n",
    "print(\"âœ… Classification report saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9e2939-8a1d-4b63-9141-a9a64eb494d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (115029, 89)\n",
      "âœ… Test shape: (28758, 89)\n",
      "ðŸ”Ž Unique classes in y_train: [ 0.66171746 -1.511219  ]\n",
      "ðŸ”Ž Unique classes in y_test: [ 0.66171746 -1.511219  ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1.511219    0.66171746]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 52\u001b[0m\n\u001b[0;32m     40\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     41\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     42\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# âœ… Step 6. Train the model\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… XGBoost training completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# âœ… Step 7. Make predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1640\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1635\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1637\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1639\u001b[0m ):\n\u001b[1;32m-> 1640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1642\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1643\u001b[0m     )\n\u001b[0;32m   1645\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1.511219    0.66171746]"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# ðŸ“ 5-Model Training and Evaluation\n",
    "# ðŸ““ 02_Baseline_XGBoost_Implementation.ipynb\n",
    "# -------------------------------------------------\n",
    "\n",
    "# âœ… Step 0. Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# âœ… Step 1. Load cleaned train-test split data\n",
    "train_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\train_data.csv\"\n",
    "test_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\test_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"âœ… Train shape:\", train_df.shape)\n",
    "print(\"âœ… Test shape:\", test_df.shape)\n",
    "\n",
    "# âœ… Step 2. Separate features and labels\n",
    "X_train = train_df.drop(columns=['Label', 'Attack_enc', 'Label_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack'], errors='ignore')\n",
    "y_train = train_df['Label_enc']\n",
    "\n",
    "X_test = test_df.drop(columns=['Label', 'Attack_enc', 'Label_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack'], errors='ignore')\n",
    "y_test = test_df['Label_enc']\n",
    "\n",
    "# âœ… Step 3. Convert labels - replace -1 with 1\n",
    "y_train = y_train.replace(-1, 1)\n",
    "y_test = y_test.replace(-1, 1)\n",
    "\n",
    "# âœ… Step 4. Confirm label classes\n",
    "print(\"ðŸ”Ž Unique classes in y_train:\", y_train.unique())\n",
    "print(\"ðŸ”Ž Unique classes in y_test:\", y_test.unique())\n",
    "\n",
    "# âœ… Step 5. Initialise XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# âœ… Step 6. Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"âœ… XGBoost training completed.\")\n",
    "\n",
    "# âœ… Step 7. Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"âœ… Predictions completed.\")\n",
    "\n",
    "# âœ… Step 8. Evaluate performance\n",
    "print(\"ðŸ”Ž Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# âœ… Step 9. Confusion Matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# âœ… Step 10. Save evaluation outputs for reporting\n",
    "report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "report_df.to_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\xgb_baseline_classification_report.csv\")\n",
    "print(\"âœ… Classification report saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67adbc61-cb63-46c3-8c24-651831ee7f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (115029, 89)\n",
      "âœ… Test shape: (28758, 89)\n",
      "ðŸ”Ž Unique classes in y_train after fix: [ 0 -1]\n",
      "ðŸ”Ž Unique classes in y_test after fix: [ 0 -1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1  0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 64\u001b[0m\n\u001b[0;32m     52\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     53\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     54\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     61\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# âœ… Step 5. Train the model\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… XGBoost training completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# âœ… Step 6. Make predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1640\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1635\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1637\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1639\u001b[0m ):\n\u001b[1;32m-> 1640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1642\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1643\u001b[0m     )\n\u001b[0;32m   1645\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1  0]"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# ðŸ“ 5-Model Training and Evaluation\n",
    "# ðŸ““ 02_Baseline_XGBoost_Implementation_Fixed.ipynb\n",
    "# -------------------------------------------------\n",
    "\n",
    "# âœ… Step 0. Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# âœ… Step 1. Load cleaned train-test split data\n",
    "train_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\train_data.csv\"\n",
    "test_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\test_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"âœ… Train shape:\", train_df.shape)\n",
    "print(\"âœ… Test shape:\", test_df.shape)\n",
    "\n",
    "# âœ… Step 2. Re-load labels from original unscaled columns if available\n",
    "# If 'Label_enc' is scaled, try using original 'Label' column if it exists\n",
    "if 'Label_enc' in train_df.columns:\n",
    "    y_train = train_df['Label_enc']\n",
    "elif 'Label' in train_df.columns:\n",
    "    y_train = train_df['Label']\n",
    "else:\n",
    "    raise ValueError(\"Label column not found in training data.\")\n",
    "\n",
    "if 'Label_enc' in test_df.columns:\n",
    "    y_test = test_df['Label_enc']\n",
    "elif 'Label' in test_df.columns:\n",
    "    y_test = test_df['Label']\n",
    "else:\n",
    "    raise ValueError(\"Label column not found in test data.\")\n",
    "\n",
    "# âœ… Convert labels to integer binary classes (assuming -1 = attack, 0 = benign)\n",
    "y_train = y_train.replace(-1, 1).astype(int)\n",
    "y_test = y_test.replace(-1, 1).astype(int)\n",
    "\n",
    "print(\"ðŸ”Ž Unique classes in y_train after fix:\", y_train.unique())\n",
    "print(\"ðŸ”Ž Unique classes in y_test after fix:\", y_test.unique())\n",
    "\n",
    "# âœ… Step 3. Separate features\n",
    "X_train = train_df.drop(columns=['Label', 'Attack_enc', 'Label_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack'], errors='ignore')\n",
    "X_test = test_df.drop(columns=['Label', 'Attack_enc', 'Label_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack'], errors='ignore')\n",
    "\n",
    "# âœ… Step 4. Initialise XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# âœ… Step 5. Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"âœ… XGBoost training completed.\")\n",
    "\n",
    "# âœ… Step 6. Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"âœ… Predictions completed.\")\n",
    "\n",
    "# âœ… Step 7. Evaluate performance\n",
    "print(\"ðŸ”Ž Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# âœ… Step 8. Confusion Matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# âœ… Step 9. Save evaluation outputs for reporting\n",
    "report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "report_df.to_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\xgb_baseline_classification_report.csv\")\n",
    "print(\"âœ… Classification report saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3070fa76-1779-4810-933e-f40126db13ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (115029, 89)\n",
      "âœ… Test shape: (28758, 89)\n",
      "ðŸ”Ž Unique classes in y_train after fix: [ 0 -1]\n",
      "ðŸ”Ž Unique classes in y_test after fix: [ 0 -1]\n",
      "ðŸ”Ž Non-numeric columns in X_train: []\n",
      "ðŸ”Ž Non-numeric columns in X_test: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1  0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 61\u001b[0m\n\u001b[0;32m     49\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     50\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     51\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# âœ… Step 7. Train the model\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… XGBoost training completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# âœ… Step 8. Make predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1640\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1635\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1637\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1639\u001b[0m ):\n\u001b[1;32m-> 1640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1642\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1643\u001b[0m     )\n\u001b[0;32m   1645\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [-1  0]"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# ðŸ“ 5-Model Training and Evaluation\n",
    "# ðŸ““ 02_Baseline_XGBoost_Implementation_FinalFix.ipynb\n",
    "# -------------------------------------------------\n",
    "\n",
    "# âœ… Step 0. Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# âœ… Step 1. Load cleaned train-test split data\n",
    "train_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\train_data.csv\"\n",
    "test_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\test_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"âœ… Train shape:\", train_df.shape)\n",
    "print(\"âœ… Test shape:\", test_df.shape)\n",
    "\n",
    "# âœ… Step 2. Reload labels from appropriate columns\n",
    "y_train = train_df['Label_enc'] if 'Label_enc' in train_df.columns else train_df['Label']\n",
    "y_test = test_df['Label_enc'] if 'Label_enc' in test_df.columns else test_df['Label']\n",
    "\n",
    "# âœ… Step 3. Convert -1 to 1 for attacks\n",
    "y_train = y_train.replace(-1, 1).astype(int)\n",
    "y_test = y_test.replace(-1, 1).astype(int)\n",
    "\n",
    "print(\"ðŸ”Ž Unique classes in y_train after fix:\", y_train.unique())\n",
    "print(\"ðŸ”Ž Unique classes in y_test after fix:\", y_test.unique())\n",
    "\n",
    "# âœ… Step 4. Separate features, drop non-numeric columns\n",
    "X_train = train_df.drop(columns=['Label', 'Attack_enc', 'Label_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack'], errors='ignore')\n",
    "X_test = test_df.drop(columns=['Label', 'Attack_enc', 'Label_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack'], errors='ignore')\n",
    "\n",
    "# âœ… Step 5. Check no remaining non-numeric columns\n",
    "non_numeric_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(\"ðŸ”Ž Non-numeric columns in X_train:\", non_numeric_cols)\n",
    "X_train = X_train.drop(columns=non_numeric_cols, errors='ignore')\n",
    "\n",
    "non_numeric_cols = X_test.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(\"ðŸ”Ž Non-numeric columns in X_test:\", non_numeric_cols)\n",
    "X_test = X_test.drop(columns=non_numeric_cols, errors='ignore')\n",
    "\n",
    "# âœ… Step 6. Initialise XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# âœ… Step 7. Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"âœ… XGBoost training completed.\")\n",
    "\n",
    "# âœ… Step 8. Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"âœ… Predictions completed.\")\n",
    "\n",
    "# âœ… Step 9. Evaluate performance\n",
    "print(\"ðŸ”Ž Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# âœ… Step 10. Confusion Matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# âœ… Step 11. Save evaluation outputs for reporting\n",
    "report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "report_df.to_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\xgb_baseline_classification_report.csv\")\n",
    "print(\"âœ… Classification report saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e8546f-c4e9-43ba-87c4-3c3b48f82f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Attack', 'Hour', 'DayOfWeek', 'FlowBytesRatio', 'Label_enc', 'Attack_enc']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\train_data.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "# Print all columns to confirm correct label field\n",
    "print(train_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac9a1f3-fed6-4c1b-815f-de70bf7e5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Unique Label_enc values: [ 0.66171746 -1.511219  ]\n",
      "ðŸ”Ž Unique Attack_enc values: [ 0.56671549 -1.67888577 -2.42741952 -1.86601921 -0.18181826  0.00531517\n",
      "  0.37958205 -0.3689517  -1.30461889 -2.24028608 -2.61455296 -1.49175233\n",
      " -0.93035202 -1.11748545 -0.74321858  0.19244861 -0.55608514 -2.05315264]\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”Ž Unique Label_enc values:\", train_df['Label_enc'].unique())\n",
    "print(\"ðŸ”Ž Unique Attack_enc values:\", train_df['Attack_enc'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c446bf0c-9670-4bc7-b426-5d23852c0f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (115029, 89)\n",
      "âœ… Test shape: (28758, 89)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Test shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# âœ… Overwrite Label_enc with fresh integer labels from raw Label column\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# If your Label was: 'Benign'=0, attacks=1, or multi-class as needed\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Adjust map as needed:\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_enc_fixed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBenign\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_enc_fixed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBenign\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ”Ž Unique Label_enc_fixed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_enc_fixed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Label'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# âœ… Load again to be 100% clean\n",
    "train_df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\train_data.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\test_data.csv\")\n",
    "\n",
    "print(\"âœ… Train shape:\", train_df.shape)\n",
    "print(\"âœ… Test shape:\", test_df.shape)\n",
    "\n",
    "# âœ… Overwrite Label_enc with fresh integer labels from raw Label column\n",
    "# If your Label was: 'Benign'=0, attacks=1, or multi-class as needed\n",
    "# Adjust map as needed:\n",
    "train_df['Label_enc_fixed'] = train_df['Label'].map(lambda x: 0 if x == 'Benign' or x == 0 else 1)\n",
    "test_df['Label_enc_fixed'] = test_df['Label'].map(lambda x: 0 if x == 'Benign' or x == 0 else 1)\n",
    "\n",
    "print(\"ðŸ”Ž Unique Label_enc_fixed:\", train_df['Label_enc_fixed'].unique())\n",
    "\n",
    "# âœ… Prepare features: drop any non-numeric + text + old label columns\n",
    "X_train = train_df.drop(columns=['Label', 'Attack', 'Label_enc', 'Attack_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Hour', 'DayOfWeek'], errors='ignore')\n",
    "y_train = train_df['Label_enc_fixed']\n",
    "\n",
    "X_test = test_df.drop(columns=['Label', 'Attack', 'Label_enc', 'Attack_enc', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Hour', 'DayOfWeek'], errors='ignore')\n",
    "y_test = test_df['Label_enc_fixed']\n",
    "\n",
    "# âœ… Final check:\n",
    "print(\"âœ… y_train classes:\", y_train.unique())\n",
    "print(\"âœ… X_train columns:\", X_train.columns.tolist())\n",
    "\n",
    "# âœ… Train baseline XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"âœ… XGBoost training completed.\")\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"ðŸ”Ž Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c785a70-1d00-41c6-bd69-68919b91b02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Train columns: ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Attack', 'Hour', 'DayOfWeek', 'FlowBytesRatio', 'Label_enc', 'Attack_enc']\n",
      "ðŸ”Ž Test columns: ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Attack', 'Hour', 'DayOfWeek', 'FlowBytesRatio', 'Label_enc', 'Attack_enc']\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”Ž Train columns:\", train_df.columns.tolist())\n",
    "print(\"ðŸ”Ž Test columns:\", test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c048c00-ffbf-4584-9f32-d29439cf8765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (115029, 89)\n",
      "âœ… Test shape: (28758, 89)\n",
      "ðŸ”Ž Unique Label_enc_fixed in train: [1]\n",
      "ðŸ”Ž Unique Label_enc_fixed in test: [1]\n",
      "ðŸ”Ž Non-numeric columns in X_train: []\n",
      "ðŸ”Ž Non-numeric columns in X_test: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0], got [1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 60\u001b[0m\n\u001b[0;32m     48\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     49\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     50\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# âœ… Step 6. Train the model\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… XGBoost training completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# âœ… Step 7. Make predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1640\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1635\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1637\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1639\u001b[0m ):\n\u001b[1;32m-> 1640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1642\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1643\u001b[0m     )\n\u001b[0;32m   1645\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0], got [1]"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# ðŸ“ 5-Model Training and Evaluation\n",
    "# ðŸ““ 02_Baseline_XGBoost_Implementation.ipynb\n",
    "# FINAL ROBUST VERSION\n",
    "# -------------------------------------------------\n",
    "\n",
    "# âœ… Step 0. Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# âœ… Step 1. Load cleaned train-test split data\n",
    "train_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\train_data.csv\"\n",
    "test_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\test_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"âœ… Train shape:\", train_df.shape)\n",
    "print(\"âœ… Test shape:\", test_df.shape)\n",
    "\n",
    "# âœ… Step 2. Map Attack column to binary Label_enc_fixed\n",
    "# If 'Attack' column has benign rows as 0 or 'Benign', else attacks\n",
    "train_df['Label_enc_fixed'] = train_df['Attack'].apply(lambda x: 0 if x in ['Benign', 0] else 1)\n",
    "test_df['Label_enc_fixed'] = test_df['Attack'].apply(lambda x: 0 if x in ['Benign', 0] else 1)\n",
    "\n",
    "# Confirm unique values\n",
    "print(\"ðŸ”Ž Unique Label_enc_fixed in train:\", train_df['Label_enc_fixed'].unique())\n",
    "print(\"ðŸ”Ž Unique Label_enc_fixed in test:\", test_df['Label_enc_fixed'].unique())\n",
    "\n",
    "# âœ… Step 3. Separate features and labels\n",
    "X_train = train_df.drop(columns=['Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack', 'Label_enc', 'Attack_enc', 'Label_enc_fixed'], errors='ignore')\n",
    "y_train = train_df['Label_enc_fixed'].astype(int)\n",
    "\n",
    "X_test = test_df.drop(columns=['Flow ID', 'Src IP', 'Dst IP', 'Timestamp', 'Attack', 'Label_enc', 'Attack_enc', 'Label_enc_fixed'], errors='ignore')\n",
    "y_test = test_df['Label_enc_fixed'].astype(int)\n",
    "\n",
    "# âœ… Step 4. Confirm no non-numeric columns\n",
    "non_numeric_cols_train = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "non_numeric_cols_test = X_test.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(\"ðŸ”Ž Non-numeric columns in X_train:\", non_numeric_cols_train)\n",
    "print(\"ðŸ”Ž Non-numeric columns in X_test:\", non_numeric_cols_test)\n",
    "\n",
    "# âœ… Step 5. Initialise XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# âœ… Step 6. Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"âœ… XGBoost training completed.\")\n",
    "\n",
    "# âœ… Step 7. Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(\"âœ… Predictions completed.\")\n",
    "\n",
    "# âœ… Step 8. Evaluate performance\n",
    "print(\"ðŸ”Ž Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# âœ… Step 9. Confusion Matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# âœ… Step 10. Save evaluation outputs for reporting\n",
    "report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "report_df.to_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\xgb_baseline_classification_report.csv\")\n",
    "print(\"âœ… Classification report saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dee82fd-9c46-4877-8121-be79e486f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Unique Attack values in train: [nan 'Length manipulation - Complete'\n",
      " 'Brute force or specific coil. Address: 1' 'Length manipulation' 'Replay'\n",
      " 'Replay - Complete' 'Stacked Modbus Frames - Complete'\n",
      " 'Recon. Range: 2000' 'Payload injection - Complete'\n",
      " 'Brute force or specific coil. Address: 13'\n",
      " 'Brute force or specific - Complete' 'Payload injection'\n",
      " 'Query flooding. Complete' 'Query Flooding' 'Recon. Complete'\n",
      " 'Stacked Modbus Frames' 'Recon. Range: 125'\n",
      " 'Brute force or specific coil. Address: 14']\n",
      "ðŸ”Ž Unique Attack values in test: [nan 'Replay' 'Query Flooding' 'Brute force or specific coil. Address: 1'\n",
      " 'Stacked Modbus Frames - Complete' 'Recon. Complete'\n",
      " 'Length manipulation' 'Brute force or specific - Complete'\n",
      " 'Recon. Range: 2000' 'Recon. Range: 125'\n",
      " 'Brute force or specific coil. Address: 13'\n",
      " 'Payload injection - Complete' 'Query flooding. Complete'\n",
      " 'Length manipulation - Complete' 'Stacked Modbus Frames'\n",
      " 'Replay - Complete' 'Payload injection'\n",
      " 'Brute force or specific coil. Address: 14']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\train_data.csv\"\n",
    "test_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\test_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"ðŸ”Ž Unique Attack values in train:\", train_df['Attack'].unique())\n",
    "print(\"ðŸ”Ž Unique Attack values in test:\", test_df['Attack'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d08c3784-3b42-45d7-b62a-2ccc84336190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\35\\ipykernel_9888\\1375686481.py:4: DtypeWarning: Columns (6,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_df = pd.read_csv(combined_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Unique Attack values in combined: ['Stacked Modbus Frames' 'Stacked Modbus Frames - Complete'\n",
      " 'Brute force or specific coil. Address: 13' 'Replay' 'Replay - Complete'\n",
      " 'Recon. Range: 2000' 'Query Flooding' 'Recon. Complete'\n",
      " 'Query flooding. Complete' 'Payload injection - Complete'\n",
      " 'Payload injection' 'Length manipulation'\n",
      " 'Length manipulation - Complete'\n",
      " 'Brute force or specific coil. Address: 1'\n",
      " 'Brute force or specific - Complete'\n",
      " 'Brute force or specific coil. Address: 14' 'Recon. Range: 125' nan]\n",
      "ðŸ”¢ Combined dataset shape: (143787, 90)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\combined_attack_benign_encoded_scaled.csv\"\n",
    "combined_df = pd.read_csv(combined_path)\n",
    "\n",
    "print(\"ðŸ”Ž Unique Attack values in combined:\", combined_df['Attack'].unique())\n",
    "print(\"ðŸ”¢ Combined dataset shape:\", combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9611773-8565-4ce6-9812-bfd5084cc7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Unique Label values in combined: ['Attack' 'Benign']\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”Ž Unique Label values in combined:\", combined_df['Label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf880f5-c6ab-45c2-9815-a58e628e8a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Combined data loaded. Shape: (143787, 88)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_path = r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\combined_attack_benign.csv\"\n",
    "combined_df = pd.read_csv(combined_path, low_memory=False)\n",
    "\n",
    "print(\"âœ… Combined data loaded. Shape:\", combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb610e6-d094-4a18-ad7a-a15f6965599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Label encoding completed. Unique values: [1]\n"
     ]
    }
   ],
   "source": [
    "combined_df['Label_enc'] = combined_df['Label'].map(lambda x: 0 if x == 'Benign' else 1)\n",
    "\n",
    "print(\"ðŸ”Ž Label encoding completed. Unique values:\", combined_df['Label_enc'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3df5bb29-d251-4f3b-abaa-5ce9702360ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Sample benign rows Attack column:\n",
      "Series([], Name: Attack, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”Ž Sample benign rows Attack column:\")\n",
    "print(combined_df[combined_df['Label_enc']==0]['Attack'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "961374be-9658-435f-9b0d-cadcefe2e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved fixed combined dataset.\n"
     ]
    }
   ],
   "source": [
    "combined_df.to_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\combined_attack_benign_fixed.csv\", index=False)\n",
    "print(\"âœ… Saved fixed combined dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d11f97-96ba-4774-ac99-06d672164f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\35\\ipykernel_9888\\2167014771.py:2: DtypeWarning: Columns (83,84,86,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\combined_attack_benign_fixed.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Label_enc distribution:\n",
      "Label_enc\n",
      "1    143787\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load your combined_attack_benign_fixed.csv to inspect Label distribution\n",
    "df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\combined_attack_benign_fixed.csv\")\n",
    "\n",
    "print(\"ðŸ”Ž Label_enc distribution:\")\n",
    "print(df['Label_enc'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bb58671-9adf-47a5-9edc-951a88b26dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\35\\ipykernel_9888\\4245764201.py:4: DtypeWarning: Columns (87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  attack_df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\final_attack_only.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Attack shape: (43787, 88)\n",
      "âœ… Benign shape: (100000, 84)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned attack dataset\n",
    "attack_df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\final_attack_only.csv\")\n",
    "\n",
    "# Load benign sampled dataset\n",
    "benign_df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\benign_sample_100k.csv\")\n",
    "\n",
    "# Confirm shapes\n",
    "print(\"âœ… Attack shape:\", attack_df.shape)\n",
    "print(\"âœ… Benign shape:\", benign_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a098938-ea99-4157-b736-8aa739fa2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels\n",
    "attack_df['Label_enc'] = 1\n",
    "benign_df['Label_enc'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e0f734f-39ab-4719-9db9-376f298eede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "combined_df = pd.concat([attack_df, benign_df], ignore_index=True)\n",
    "\n",
    "# Shuffle to mix benign and attack rows randomly (optional but recommended)\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8316aa9c-f2e6-4575-8ac7-4eecde6916cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final combined attack + benign dataset saved.\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "combined_df.to_csv(r\"C:\\Users\\Administrator\\Desktop\\Saif\\CIC_Modbus_Research\\Final_Clean_Merged\\combined_attack_benign_final.csv\", index=False)\n",
    "print(\"âœ… Final combined attack + benign dataset saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d97c0817-824b-4341-bf8c-0fdfd4676a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Final Label_enc distribution:\n",
      "Label_enc\n",
      "0    100000\n",
      "1     43787\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check distribution\n",
    "print(\"ðŸ”Ž Final Label_enc distribution:\")\n",
    "print(combined_df['Label_enc'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b4c03-6ece-4791-a753-6976c520b90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
